{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of chars: 82\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "import math\n",
    "\n",
    "txt_files=nltk.corpus.gutenberg.fileids()[0:5]\n",
    "char_corpus = gutenberg.raw(txt_files)\n",
    "\n",
    "\n",
    "chars = sorted(list(set(char_corpus)))\n",
    "print('total number of chars:', len(chars))\n",
    "c2i = dict((c, i) for i, c in enumerate(chars))\n",
    "i2c = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "length = 50+1\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(char_corpus) - length):\n",
    "    sentences.append(char_corpus[i: i + length])\n",
    "    next_chars.append(char_corpus[i + length])\n",
    "\n",
    "x = np.zeros((len(sentences), length, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, c2i[char]] = 1\n",
    "    y[i, c2i[next_chars[i]]] = 1\n",
    "\n",
    "    \n",
    "\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=.1)\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "# build the model: a single LSTM\n",
    "print('Training char model on 100 epochs on 5 files')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(length, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    model_json = model.to_json()\n",
    "    with open(\"char_model{}.json\".format(epoch), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"char_model{}.h5\".format(epoch))\n",
    "\n",
    "\n",
    "model.fit(x, y, batch_size=128, epochs=100,callbacks=[LambdaCallback(on_epoch_end=on_epoch_end)])\n",
    "\n",
    "loss=model.evaluate(xtest,ytest,batch_size=128, verbose=1)\n",
    "print(\"perperxility is:\",math.exp(loss))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x13a5ef4e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
