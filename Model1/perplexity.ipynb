{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinmittal/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:73: UserWarning: h5py is running against HDF5 1.10.1 when it was built against 1.8.4, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17252\n",
      "(104220, 51)\n",
      "104220/104220 [==============================] - 162s 2ms/step\n",
      "[5.402609826506866, 0.17118595279274232]\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    " \n",
    " \n",
    "import string\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import matplotlib\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import keras\n",
    "import tensorflow\n",
    "from keras.utils import * \n",
    "from keras.models import *\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from pickle import dump\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Embedding\n",
    "\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# load the model\n",
    "model = load_model('model.h5')\n",
    " \n",
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer.pkl', 'rb'))\n",
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)\n",
    "# load\n",
    "in_filename = 'test_files_merged.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = list(doc.split('\\n'))\n",
    "#lines = load_doc('word_sequences_test.txt')\n",
    "\n",
    "\n",
    "\n",
    "sequences_c = tokenizer.texts_to_sequences(lines)\n",
    "#sequences = np.zeros((len(sequences_c),51))\n",
    "sequences = []\t\n",
    "for sequence in  sequences_c:\n",
    "    if(len(sequence)==51):\n",
    "        sequences.append(sequence)\n",
    "\n",
    "\n",
    "# separate into input and output\n",
    "sequences =  np.asarray(sequences)\n",
    "print(sequences.shape)\n",
    "X_test, y_test = sequences[:,:-1], sequences[:,-1]\n",
    "#X =   sequences[:,:-1]\n",
    "y_test = to_categorical(y_test, num_classes=vocab_size)\n",
    " \n",
    "\n",
    "loss = model.evaluate(X_test,y_test,batch_size=128, verbose=1)\n",
    "print(loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221.98500321544046"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(loss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
